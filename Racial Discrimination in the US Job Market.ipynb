{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examining Racial Discrimination in the US Job Market\n",
    "\n",
    "## Background\n",
    "\n",
    "Racial discrimination continues to be pervasive in cultures throughout the world. Researchers examined the level of racial discrimination in the United States labor market by randomly assigning identical résumés to black-sounding or white-sounding names and observing the impact on requests for interviews from employers.\n",
    "\n",
    "## Data\n",
    "\n",
    "In the dataset provided, each row represents a resume. The 'race' column has two values, 'b' and 'w', indicating black-sounding and white-sounding. The column 'call' has two values, 1 and 0, indicating whether the resume received a call from employers or not.\n",
    "\n",
    "Note that the 'b' and 'w' values in race are assigned randomly to the resumes when presented to the employer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.io.stata.read_stata('us_job_market_discrimination.dta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of callbacks for black-sounding names\n",
    "sum(data[data.race=='b'].call)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of callbacks for white-sounding names\n",
    "sum(data[data.race=='w'].call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race</th>\n",
       "      <th>call</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>w</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>w</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>w</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  race  call\n",
       "0    w   0.0\n",
       "1    w   0.0\n",
       "2    b   0.0\n",
       "3    b   0.0\n",
       "4    w   0.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['race','call']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4870 entries, 0 to 4869\n",
      "Data columns (total 65 columns):\n",
      "id                    4870 non-null object\n",
      "ad                    4870 non-null object\n",
      "education             4870 non-null int8\n",
      "ofjobs                4870 non-null int8\n",
      "yearsexp              4870 non-null int8\n",
      "honors                4870 non-null int8\n",
      "volunteer             4870 non-null int8\n",
      "military              4870 non-null int8\n",
      "empholes              4870 non-null int8\n",
      "occupspecific         4870 non-null int16\n",
      "occupbroad            4870 non-null int8\n",
      "workinschool          4870 non-null int8\n",
      "email                 4870 non-null int8\n",
      "computerskills        4870 non-null int8\n",
      "specialskills         4870 non-null int8\n",
      "firstname             4870 non-null object\n",
      "sex                   4870 non-null object\n",
      "race                  4870 non-null object\n",
      "h                     4870 non-null float32\n",
      "l                     4870 non-null float32\n",
      "call                  4870 non-null float32\n",
      "city                  4870 non-null object\n",
      "kind                  4870 non-null object\n",
      "adid                  4870 non-null float32\n",
      "fracblack             4784 non-null float32\n",
      "fracwhite             4784 non-null float32\n",
      "lmedhhinc             4784 non-null float32\n",
      "fracdropout           4784 non-null float32\n",
      "fraccolp              4784 non-null float32\n",
      "linc                  4784 non-null float32\n",
      "col                   4870 non-null float32\n",
      "expminreq             4870 non-null object\n",
      "schoolreq             4870 non-null object\n",
      "eoe                   4870 non-null float32\n",
      "parent_sales          1672 non-null float32\n",
      "parent_emp            1722 non-null float32\n",
      "branch_sales          608 non-null float32\n",
      "branch_emp            658 non-null float32\n",
      "fed                   3102 non-null float32\n",
      "fracblack_empzip      1918 non-null float32\n",
      "fracwhite_empzip      1918 non-null float32\n",
      "lmedhhinc_empzip      1908 non-null float32\n",
      "fracdropout_empzip    1918 non-null float32\n",
      "fraccolp_empzip       1918 non-null float32\n",
      "linc_empzip           1918 non-null float32\n",
      "manager               4870 non-null float32\n",
      "supervisor            4870 non-null float32\n",
      "secretary             4870 non-null float32\n",
      "offsupport            4870 non-null float32\n",
      "salesrep              4870 non-null float32\n",
      "retailsales           4870 non-null float32\n",
      "req                   4870 non-null float32\n",
      "expreq                4870 non-null float32\n",
      "comreq                4870 non-null float32\n",
      "educreq               4870 non-null float32\n",
      "compreq               4870 non-null float32\n",
      "orgreq                4870 non-null float32\n",
      "manuf                 4870 non-null float32\n",
      "transcom              4870 non-null float32\n",
      "bankreal              4870 non-null float32\n",
      "trade                 4870 non-null float32\n",
      "busservice            4870 non-null float32\n",
      "othservice            4870 non-null float32\n",
      "missind               4870 non-null float32\n",
      "ownership             4870 non-null object\n",
      "dtypes: float32(42), int16(1), int8(12), object(10)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Does race has a significant impact on the rate of callbacks for resumes?\n",
    "\n",
    "n= 4870 which is larger enough to use CLT for this problem. I think the appropriate tests are the z-test and the t-tests. I would use the z-test instead of t-test because the size of the sample is large enough.\n",
    " \n",
    "H0:There is no impact of race on the callbacks for resumes.\n",
    "\n",
    "H1:There is an impact of race on the callbacks for resumes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from statsmodels.stats import weightstats as stests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=data.set_index('race')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_w=df.loc['w']\n",
    "df_b=df.loc['b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2435.000000\n",
       "mean        0.096509\n",
       "std         0.295346\n",
       "min         0.000000\n",
       "25%         0.000000\n",
       "50%         0.000000\n",
       "75%         0.000000\n",
       "max         1.000000\n",
       "Name: call, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_w['call'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2435.000000\n",
       "mean        0.064476\n",
       "std         0.245649\n",
       "min         0.000000\n",
       "25%         0.000000\n",
       "50%         0.000000\n",
       "75%         0.000000\n",
       "max         1.000000\n",
       "Name: call, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_b['call'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Margin of Error: 0.015255406349886438\n",
      "confidence interval: (0.016777447859559147, 0.047288260559332024)\n",
      "p: 3.8767429116085706e-05\n",
      "reject null hypothesis\n"
     ]
    }
   ],
   "source": [
    "#the frequentist tests\n",
    "z_value = 1.96\n",
    "# white call backs\n",
    "w_prob = sum(df_w['call']) / len(df_w['call'])\n",
    "prop_w_call = 235/2435\n",
    "w_std_err = np.sqrt((w_prob * (1 - w_prob) / len(df_w['call'])))\n",
    "# black call backs\n",
    "b_prob = sum(df_b['call']) / len(df_b['call'])\n",
    "prop_b_call = 157/2435\n",
    "b_std_err = np.sqrt((b_prob * (1 - b_prob) / len(df_b['call'])))\n",
    "# Margin of error\n",
    "std_err_dif = np.sqrt((w_std_err ** 2 + b_std_err ** 2))\n",
    "margin_err_diff = z_value * std_err_dif\n",
    "print('Margin of Error:', margin_err_diff)\n",
    "# confidence interval\n",
    "prob_diff = w_prob - b_prob\n",
    "conf_int = (prob_diff - margin_err_diff, prob_diff + margin_err_diff)\n",
    "print('confidence interval:', conf_int)\n",
    "# z-test\n",
    "(ztest ,pval)=stests.ztest(df_w['call'], x2=df_b['call'], value=0,alternative='two-sided')\n",
    "print('p:',float(pval1))\n",
    "if pval<0.05:\n",
    "    print(\"reject null hypothesis\")\n",
    "else:\n",
    "    print(\"accept null hypothesis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p:  0.0\n",
      "confidence intervals: [-0.01560576  0.01560576]\n"
     ]
    }
   ],
   "source": [
    "#Bootstrap test\n",
    "def permutation_sample(data1, data2):\n",
    "    data = np.concatenate((data1,data2))\n",
    "    permuted_data = np.random.permutation(data)\n",
    "    perm_sample_1 = permuted_data[:len(data1)]\n",
    "    perm_sample_2 = permuted_data[len(data1):]\n",
    "    return perm_sample_1, perm_sample_2\n",
    "def draw_perm_reps(data_1, data_2, func, size=1):\n",
    "    perm_replicates = np.empty(size)\n",
    "    for i in range(size):\n",
    "        perm_sample_1, perm_sample_2 = permutation_sample(data_1,data_2)\n",
    "        perm_replicates[i] = func(perm_sample_1,perm_sample_2)\n",
    "    return perm_replicates\n",
    "def dif_of_mean(data_1, data_2):\n",
    "    return np.mean(data_1) - np.mean(data_2)\n",
    "perm_replicates=draw_perm_reps(df_w['call'],df_b['call'],dif_of_mean,10000)\n",
    "emp_mean=dif_of_mean(df_w['call'],df_b['call'])\n",
    "p = np.sum(perm_replicates >= emp_mean) / len(perm_replicates)\n",
    "print('p: ',p)\n",
    "conf_int = np.percentile(perm_replicates,[2.5,97.5])\n",
    "print('confidence intervals:',conf_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p-value is very small, so that we can reject the null hypothesis. There is a 3% difference for the number of callbacks between two races. It means there is a relation between the race and the number of callbacks. However, we did not check the association between the other variables and the callbacks. Therefore we cannot conclude the race is the only reason for the difference."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
